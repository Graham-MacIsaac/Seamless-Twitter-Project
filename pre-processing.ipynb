{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f83bc314",
   "metadata": {},
   "source": [
    "### Seamless Bay Area Tweet Analysis: Part 3, Pre-Processing\n",
    "\n",
    "\n",
    "The goal of this project is to analyze the twitter account of the nonprofit group Seamless Bay Area and determine what makes up the most high-impact tweet as measured by engagements.\n",
    "\n",
    "In part three we pre-process the data to prepare it for modeling. We need to perform all the feature engineering that I suspect will be necessary for the modeling step. Specifically, I want to identify links/attached media, @replies (when the tweet references another twitter account), calls to action, and sentiment score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "43c706ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as stat\n",
    "import re\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "cce8e9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/grahamsmith/Documents/SpringboardWork/Seamless_Twitter_Analysis/cleaned tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "a540d66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweet text</th>\n",
       "      <th>time</th>\n",
       "      <th>impressions</th>\n",
       "      <th>engagements</th>\n",
       "      <th>engagement rate</th>\n",
       "      <th>retweets</th>\n",
       "      <th>replies</th>\n",
       "      <th>likes</th>\n",
       "      <th>user profile clicks</th>\n",
       "      <th>url clicks</th>\n",
       "      <th>tweet words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@MTCBATA is looking for a new Executive Direct...</td>\n",
       "      <td>2018-10-27 18:01:00</td>\n",
       "      <td>124.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.040323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>['@mtcbata', 'is', 'looking', 'for', 'a', 'new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ultimate seamlessness. https://t.co/CdCLrg2o6a</td>\n",
       "      <td>2018-10-26 14:24:00</td>\n",
       "      <td>345.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>['ultimate', 'seamlessness.', 'https://t.co/cd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Help Nix Prop 6! Save funding for more seamles...</td>\n",
       "      <td>2018-10-26 02:28:00</td>\n",
       "      <td>994.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.019115</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['help', 'nix', 'prop', 'save', 'funding', 'fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>It doesn't have to be this way! Let's get to f...</td>\n",
       "      <td>2018-10-23 23:29:00</td>\n",
       "      <td>792.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.008838</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['it', \"doesn't\", 'have', 'to', 'be', 'this', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>And then come say hi at next month’s @SPUR_Urb...</td>\n",
       "      <td>2018-10-23 23:09:00</td>\n",
       "      <td>532.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.005639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['and', 'then', 'come', 'say', 'hi', 'at', 'ne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                         Tweet text  \\\n",
       "0           0  @MTCBATA is looking for a new Executive Direct...   \n",
       "1           1     Ultimate seamlessness. https://t.co/CdCLrg2o6a   \n",
       "2           2  Help Nix Prop 6! Save funding for more seamles...   \n",
       "3           3  It doesn't have to be this way! Let's get to f...   \n",
       "4           4  And then come say hi at next month’s @SPUR_Urb...   \n",
       "\n",
       "                  time  impressions  engagements  engagement rate  retweets  \\\n",
       "0  2018-10-27 18:01:00        124.0          5.0         0.040323       0.0   \n",
       "1  2018-10-26 14:24:00        345.0         10.0         0.028986       0.0   \n",
       "2  2018-10-26 02:28:00        994.0         19.0         0.019115       4.0   \n",
       "3  2018-10-23 23:29:00        792.0          7.0         0.008838       2.0   \n",
       "4  2018-10-23 23:09:00        532.0          3.0         0.005639       0.0   \n",
       "\n",
       "   replies  likes  user profile clicks  url clicks  \\\n",
       "0      0.0    0.0                  1.0         4.0   \n",
       "1      0.0    1.0                  0.0         9.0   \n",
       "2      0.0    5.0                  3.0         5.0   \n",
       "3      0.0    4.0                  1.0         0.0   \n",
       "4      0.0    1.0                  2.0         0.0   \n",
       "\n",
       "                                         tweet words  \n",
       "0  ['@mtcbata', 'is', 'looking', 'for', 'a', 'new...  \n",
       "1  ['ultimate', 'seamlessness.', 'https://t.co/cd...  \n",
       "2  ['help', 'nix', 'prop', 'save', 'funding', 'fo...  \n",
       "3  ['it', \"doesn't\", 'have', 'to', 'be', 'this', ...  \n",
       "4  ['and', 'then', 'come', 'say', 'hi', 'at', 'ne...  "
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#once again, here is our data for reference\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c323238",
   "metadata": {},
   "source": [
    "First we do a bunch of wrangling to get the links from every tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "406d6bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a space to the end of every tweet so we can find links at the end of tweets\n",
    "temp = []\n",
    "for x in range(len(df)):\n",
    "    temp.append(df['Tweet text'][x] + ' ')\n",
    "df['Tweet text'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "702413b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find every sub-string that's \"https:// + some characters + a space\"\n",
    "links = []\n",
    "for x in range(len(df)):\n",
    "    a = re.findall(r'https://.* ', df['Tweet text'].iloc[x])\n",
    "    links.append(a)\n",
    "df['links'] = links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "e8290062",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do a bunch of annoying cleaning so that each item is a nice list of links\n",
    "temp = []\n",
    "\n",
    "for x in range(len(df)):\n",
    "    temp.append(re.split('\\s', str(df['links'][x])))\n",
    "\n",
    "for x in range(len(temp)):\n",
    "    temp[x] = temp[x][0:-1]\n",
    "\n",
    "for x in range(len(temp)):\n",
    "    temp[x] = re.sub('\\[', '', str(temp[x]))\n",
    "    \n",
    "for x in range(len(temp)):\n",
    "    temp[x] = re.sub('\\]', '', str(temp[x]))\n",
    "    \n",
    "for x in range(len(temp)):\n",
    "    temp[x] = re.sub('\\'', '', str(temp[x]))\n",
    "\n",
    "for x in range(len(temp)):\n",
    "    temp[x] = re.sub('\\\"', '', str(temp[x]))\n",
    "\n",
    "df['links'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "26ac035b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                https://t.co/Syf9exwPTd\n",
       "1                                https://t.co/CdCLrg2o6a\n",
       "2       https://t.co/qM4M7tCFVO, https://t.co/2379qGdY2D\n",
       "3                                https://t.co/FczQtLbH5d\n",
       "4                                                       \n",
       "                              ...                       \n",
       "2244                             https://t.co/3xZS0tU1xD\n",
       "2245                             https://t.co/43v9okaDWZ\n",
       "2246                             https://t.co/VVZZuPjmw1\n",
       "2247                                                    \n",
       "2248                             https://t.co/BJMSIraGwy\n",
       "Name: links, Length: 2249, dtype: object"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#double check that it looks good\n",
    "df['links']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a602e5e",
   "metadata": {},
   "source": [
    "Next we'll pull out all the replies to other twitter accounts contained within the tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "8e2be610",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for some reason the way I split the words previously didn't work, so I've gone over it again\n",
    "replies = []\n",
    "for x in range(len(df)):\n",
    "    a = re.split(' ', df['Tweet text'].iloc[x])\n",
    "    replies.append(a)\n",
    "\n",
    "df['replies_sentance'] = replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "b8b367c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find all the replies, aka sub-strings starting with @\n",
    "temp3 = []\n",
    "for z in range(len(df)):\n",
    "    temp = []\n",
    "    for x in df['replies_sentance'][z]:\n",
    "        temp.append(re.findall(r'@.*', x))\n",
    "    temp2 = []\n",
    "    for y in temp:\n",
    "        if len(y) > 0:\n",
    "            temp2.append(y)\n",
    "    temp3.append(temp2)\n",
    "df['replies'] = temp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "ba2dc24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put it into a list\n",
    "temp = []\n",
    "for x in df['replies']:\n",
    "    temp.append(list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "df6034ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I couldn't get the dummies to work further down so I converted it into a string, and then split\n",
    "#it again\n",
    "temp = []\n",
    "for x in df['replies']:\n",
    "    if len(x) > 0:\n",
    "        a = re.sub('\\[', '', str(x))\n",
    "        b = re.sub('\\]', '', a)\n",
    "        c = re.sub('\\'', '', b)\n",
    "        d = re.sub('\\,', '', c)\n",
    "        temp.append(re.split(' ', d))\n",
    "    else:\n",
    "        temp.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "9459412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split each of the first 5 replies into a seperate column, so that dummies can be made\n",
    "rep = []\n",
    "rep1 = []\n",
    "rep2 = []\n",
    "rep3 = []\n",
    "\n",
    "for x in range(len(temp)):\n",
    "    if len(temp[x]) == 0:\n",
    "        rep.append('')\n",
    "        rep1.append('')\n",
    "        rep2.append('')\n",
    "        rep3.append('')\n",
    "    if len(temp[x]) == 1:\n",
    "        rep.append(temp[x][0])\n",
    "        rep1.append('')\n",
    "        rep2.append('')\n",
    "        rep3.append('')\n",
    "    if len(temp[x]) == 2:\n",
    "        rep.append(temp[x][0])\n",
    "        rep1.append(temp[x][1])\n",
    "        rep2.append('')\n",
    "        rep3.append('')\n",
    "    if len(temp[x]) == 3:\n",
    "        rep.append(temp[x][0])\n",
    "        rep1.append(temp[x][1])\n",
    "        rep2.append(temp[x][2])\n",
    "        rep3.append('')\n",
    "    if len(temp[x]) >= 4:\n",
    "        rep.append(temp[x][0])\n",
    "        rep1.append(temp[x][1])\n",
    "        rep2.append(temp[x][2])\n",
    "        rep3.append(temp[x][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "1294b3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a dataframe that we'll use for the dummies\n",
    "df1 = pd.DataFrame()\n",
    "df1['engagements'] = df['engagements']\n",
    "df1['rep'] = rep\n",
    "df1['rep1'] = rep1\n",
    "df1['rep2'] = rep2\n",
    "df1['rep3'] = rep3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "7bd00afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engagements</th>\n",
       "      <th>rep</th>\n",
       "      <th>rep1</th>\n",
       "      <th>rep2</th>\n",
       "      <th>rep3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>@MTCBATA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>@SPUR_Urbanist</td>\n",
       "      <td>@icgee</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   engagements             rep    rep1 rep2 rep3\n",
       "0          5.0        @MTCBATA                  \n",
       "1         10.0                                  \n",
       "2         19.0                                  \n",
       "3          7.0                                  \n",
       "4          3.0  @SPUR_Urbanist  @icgee          "
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#double check that it looks okay with one dummy per column\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "c0d50f12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engagements</th>\n",
       "      <th>rep_</th>\n",
       "      <th>rep_\"@AsmMarcBermans\"</th>\n",
       "      <th>rep_\"@Caltrains\"</th>\n",
       "      <th>rep_\"@DavidChius\"</th>\n",
       "      <th>rep_\"@GavinNewsoms\"</th>\n",
       "      <th>rep_\"@MTCBATAs\"</th>\n",
       "      <th>rep_\"@MetroTransitMNs\"</th>\n",
       "      <th>rep_\"@MosesMaynez\"</th>\n",
       "      <th>rep_\"@RepHankJohnsons\"</th>\n",
       "      <th>...</th>\n",
       "      <th>rep3_@sfmta_muni</th>\n",
       "      <th>rep3_@skbarz</th>\n",
       "      <th>rep3_@stevepepple</th>\n",
       "      <th>rep3_@theGreaterMarin</th>\n",
       "      <th>rep3_@thecliffbar</th>\n",
       "      <th>rep3_@transpoakland</th>\n",
       "      <th>rep3_@urbenschneider</th>\n",
       "      <th>rep3_@wpusanews.</th>\n",
       "      <th>rep3_@xentrans!</th>\n",
       "      <th>rep3_@yimbyyy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2244</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2245</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2246</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2247</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2248</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2249 rows × 926 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      engagements  rep_  rep_\"@AsmMarcBermans\"  rep_\"@Caltrains\"  \\\n",
       "0             5.0     0                      0                 0   \n",
       "1            10.0     1                      0                 0   \n",
       "2            19.0     1                      0                 0   \n",
       "3             7.0     1                      0                 0   \n",
       "4             3.0     0                      0                 0   \n",
       "...           ...   ...                    ...               ...   \n",
       "2244         13.0     1                      0                 0   \n",
       "2245          6.0     0                      0                 0   \n",
       "2246          2.0     1                      0                 0   \n",
       "2247          6.0     0                      0                 0   \n",
       "2248         19.0     0                      0                 0   \n",
       "\n",
       "      rep_\"@DavidChius\"  rep_\"@GavinNewsoms\"  rep_\"@MTCBATAs\"  \\\n",
       "0                     0                    0                0   \n",
       "1                     0                    0                0   \n",
       "2                     0                    0                0   \n",
       "3                     0                    0                0   \n",
       "4                     0                    0                0   \n",
       "...                 ...                  ...              ...   \n",
       "2244                  0                    0                0   \n",
       "2245                  0                    0                0   \n",
       "2246                  0                    0                0   \n",
       "2247                  0                    0                0   \n",
       "2248                  0                    0                0   \n",
       "\n",
       "      rep_\"@MetroTransitMNs\"  rep_\"@MosesMaynez\"  rep_\"@RepHankJohnsons\"  ...  \\\n",
       "0                          0                   0                       0  ...   \n",
       "1                          0                   0                       0  ...   \n",
       "2                          0                   0                       0  ...   \n",
       "3                          0                   0                       0  ...   \n",
       "4                          0                   0                       0  ...   \n",
       "...                      ...                 ...                     ...  ...   \n",
       "2244                       0                   0                       0  ...   \n",
       "2245                       0                   0                       0  ...   \n",
       "2246                       0                   0                       0  ...   \n",
       "2247                       0                   0                       0  ...   \n",
       "2248                       0                   0                       0  ...   \n",
       "\n",
       "      rep3_@sfmta_muni  rep3_@skbarz  rep3_@stevepepple  \\\n",
       "0                    0             0                  0   \n",
       "1                    0             0                  0   \n",
       "2                    0             0                  0   \n",
       "3                    0             0                  0   \n",
       "4                    0             0                  0   \n",
       "...                ...           ...                ...   \n",
       "2244                 0             0                  0   \n",
       "2245                 0             0                  0   \n",
       "2246                 0             0                  0   \n",
       "2247                 0             0                  0   \n",
       "2248                 0             0                  0   \n",
       "\n",
       "      rep3_@theGreaterMarin  rep3_@thecliffbar  rep3_@transpoakland  \\\n",
       "0                         0                  0                    0   \n",
       "1                         0                  0                    0   \n",
       "2                         0                  0                    0   \n",
       "3                         0                  0                    0   \n",
       "4                         0                  0                    0   \n",
       "...                     ...                ...                  ...   \n",
       "2244                      0                  0                    0   \n",
       "2245                      0                  0                    0   \n",
       "2246                      0                  0                    0   \n",
       "2247                      0                  0                    0   \n",
       "2248                      0                  0                    0   \n",
       "\n",
       "      rep3_@urbenschneider  rep3_@wpusanews.  rep3_@xentrans!  rep3_@yimbyyy  \n",
       "0                        0                 0                0              0  \n",
       "1                        0                 0                0              0  \n",
       "2                        0                 0                0              0  \n",
       "3                        0                 0                0              0  \n",
       "4                        0                 0                0              0  \n",
       "...                    ...               ...              ...            ...  \n",
       "2244                     0                 0                0              0  \n",
       "2245                     0                 0                0              0  \n",
       "2246                     0                 0                0              0  \n",
       "2247                     0                 0                0              0  \n",
       "2248                     0                 0                0              0  \n",
       "\n",
       "[2249 rows x 926 columns]"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split into dummies\n",
    "df1 = pd.get_dummies(df1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "199fb69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024589337340945483"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just out of curiosity, is there a linear relationship between replies an d\n",
    "scores = []\n",
    "for reply in df1.columns[15:]:\n",
    "    x = np.array(df1[str(reply)]).reshape(-1, 1)\n",
    "    y = df1['engagements']\n",
    "    model = LinearRegression().fit(x, y)\n",
    "    scores.append(model.score(x, y))\n",
    "np.max(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd23cf82",
   "metadata": {},
   "source": [
    "Oof, well if an r^2 of 0.0246 is the best we can get that probably isn't a productive line of inquiry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a2cea5",
   "metadata": {},
   "source": [
    "Moving on to the last feature I want to create: sentiment score. I'll be doing this by getting a list of positive and negative words, then comparing each tweet and assigning it a score from -1 to 1 based on how many (if any) of those words it has. This list was downloaded from Kaggle (https://www.kaggle.com/datasets/mukulkirti/positive-and-negative-word-listrar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "c3035ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.read_excel('/Users/grahamsmith/Documents/SpringboardWork/Positive and Negative Word List.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "5fcc5df0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Negative Sense Word List</th>\n",
       "      <th>Positive Sense Word List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>able</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>abolish</td>\n",
       "      <td>abundance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>abominable</td>\n",
       "      <td>accelerate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>abominably</td>\n",
       "      <td>accept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4716</th>\n",
       "      <td>4716</td>\n",
       "      <td>zenana</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4717</th>\n",
       "      <td>4717</td>\n",
       "      <td>zephyr</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4718</th>\n",
       "      <td>4718</td>\n",
       "      <td>zero</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4719</th>\n",
       "      <td>4719</td>\n",
       "      <td>zol</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4720</th>\n",
       "      <td>4720</td>\n",
       "      <td>zombie</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4721 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 Negative Sense Word List Positive Sense Word List\n",
       "0              0                      NaN                      NaN\n",
       "1              1                 abnormal                     able\n",
       "2              2                  abolish                abundance\n",
       "3              3               abominable               accelerate\n",
       "4              4               abominably                   accept\n",
       "...          ...                      ...                      ...\n",
       "4716        4716                   zenana                      NaN\n",
       "4717        4717                   zephyr                      NaN\n",
       "4718        4718                     zero                      NaN\n",
       "4719        4719                      zol                      NaN\n",
       "4720        4720                   zombie                      NaN\n",
       "\n",
       "[4721 rows x 3 columns]"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72acde6",
   "metadata": {},
   "source": [
    "First we find the number of positive words in each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "741bfe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for x in words['Negative Sense Word List']:\n",
    "    temp.append(str(x))\n",
    "words['Negative Sense Words'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "2bcad3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for x in df['tweet words']:\n",
    "    temp.append([ele for ele in list(words['Negative Sense Words']) if(ele in str(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "255836b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Negative words'] = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2b690d",
   "metadata": {},
   "source": [
    "Then we find the number of positive words in each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "49016865",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for x in words['Positive Sense Word List']:\n",
    "    temp.append(str(x))\n",
    "words['Positive Sense Words'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "6f97dd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for x in df['tweet words']:\n",
    "    temp.append([ele for ele in list(words['Positive Sense Words']) if(ele in str(x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "3915a0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Positive words'] = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a525b7",
   "metadata": {},
   "source": [
    "Sentiment score is calculated by subtracting the number of negative words in the tweet from the number of positive words and dividing it by the total number of words to find a ratio of positive:negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "5ad6c3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for x in range(len(df)):\n",
    "    temp.append(len(df['Positive words'][x]) - len(df['Negative words'][x])/len(df['Tweet text'][x]))\n",
    "df['Sentiment Score'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "15cfb5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#While we're at it, lets pull out the stopwords from the words list too\n",
    "stopwords = [\"0o\", \"0s\", \"3a\", \"3b\", \"3d\", \"6b\", \"6o\", \"a\", \"a1\", \"a2\", \"a3\", \"a4\", \"ab\", \"able\", \"about\", \"above\", \"abst\", \"ac\", \"accordance\", \"according\", \"accordingly\", \"across\", \"act\", \"actually\", \"ad\", \"added\", \"adj\", \"ae\", \"af\", \"affected\", \"affecting\", \"affects\", \"after\", \"afterwards\", \"ag\", \"again\", \"against\", \"ah\", \"ain\", \"ain't\", \"aj\", \"al\", \"all\", \"allow\", \"allows\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\", \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"announce\", \"another\", \"any\", \"anybody\", \"anyhow\", \"anymore\", \"anyone\", \"anything\", \"anyway\", \"anyways\", \"anywhere\", \"ao\", \"ap\", \"apart\", \"apparently\", \"appear\", \"appreciate\", \"appropriate\", \"approximately\", \"ar\", \"are\", \"aren\", \"arent\", \"aren't\", \"arise\", \"around\", \"as\", \"a's\", \"aside\", \"ask\", \"asking\", \"associated\", \"at\", \"au\", \"auth\", \"av\", \"available\", \"aw\", \"away\", \"awfully\", \"ax\", \"ay\", \"az\", \"b\", \"b1\", \"b2\", \"b3\", \"ba\", \"back\", \"bc\", \"bd\", \"be\", \"became\", \"because\", \"become\", \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"begin\", \"beginning\", \"beginnings\", \"begins\", \"behind\", \"being\", \"believe\", \"below\", \"beside\", \"besides\", \"best\", \"better\", \"between\", \"beyond\", \"bi\", \"bill\", \"biol\", \"bj\", \"bk\", \"bl\", \"bn\", \"both\", \"bottom\", \"bp\", \"br\", \"brief\", \"briefly\", \"bs\", \"bt\", \"bu\", \"but\", \"bx\", \"by\", \"c\", \"c1\", \"c2\", \"c3\", \"ca\", \"call\", \"came\", \"can\", \"cannot\", \"cant\", \"can't\", \"cause\", \"causes\", \"cc\", \"cd\", \"ce\", \"certain\", \"certainly\", \"cf\", \"cg\", \"ch\", \"changes\", \"ci\", \"cit\", \"cj\", \"cl\", \"clearly\", \"cm\", \"c'mon\", \"cn\", \"co\", \"com\", \"come\", \"comes\", \"con\", \"concerning\", \"consequently\", \"consider\", \"considering\", \"contain\", \"containing\", \"contains\", \"corresponding\", \"could\", \"couldn\", \"couldnt\", \"couldn't\", \"course\", \"cp\", \"cq\", \"cr\", \"cry\", \"cs\", \"c's\", \"ct\", \"cu\", \"currently\", \"cv\", \"cx\", \"cy\", \"cz\", \"d\", \"d2\", \"da\", \"date\", \"dc\", \"dd\", \"de\", \"definitely\", \"describe\", \"described\", \"despite\", \"detail\", \"df\", \"di\", \"did\", \"didn\", \"didn't\", \"different\", \"dj\", \"dk\", \"dl\", \"do\", \"does\", \"doesn\", \"doesn't\", \"doing\", \"don\", \"done\", \"don't\", \"down\", \"downwards\", \"dp\", \"dr\", \"ds\", \"dt\", \"du\", \"due\", \"during\", \"dx\", \"dy\", \"e\", \"e2\", \"e3\", \"ea\", \"each\", \"ec\", \"ed\", \"edu\", \"ee\", \"ef\", \"effect\", \"eg\", \"ei\", \"eight\", \"eighty\", \"either\", \"ej\", \"el\", \"eleven\", \"else\", \"elsewhere\", \"em\", \"empty\", \"en\", \"end\", \"ending\", \"enough\", \"entirely\", \"eo\", \"ep\", \"eq\", \"er\", \"es\", \"especially\", \"est\", \"et\", \"et-al\", \"etc\", \"eu\", \"ev\", \"even\", \"ever\", \"every\", \"everybody\", \"everyone\", \"everything\", \"everywhere\", \"ex\", \"exactly\", \"example\", \"except\", \"ey\", \"f\", \"f2\", \"fa\", \"far\", \"fc\", \"few\", \"ff\", \"fi\", \"fifteen\", \"fifth\", \"fify\", \"fill\", \"find\", \"fire\", \"first\", \"five\", \"fix\", \"fj\", \"fl\", \"fn\", \"fo\", \"followed\", \"following\", \"follows\", \"for\", \"former\", \"formerly\", \"forth\", \"forty\", \"found\", \"four\", \"fr\", \"from\", \"front\", \"fs\", \"ft\", \"fu\", \"full\", \"further\", \"furthermore\", \"fy\", \"g\", \"ga\", \"gave\", \"ge\", \"get\", \"gets\", \"getting\", \"gi\", \"give\", \"given\", \"gives\", \"giving\", \"gj\", \"gl\", \"go\", \"goes\", \"going\", \"gone\", \"got\", \"gotten\", \"gr\", \"greetings\", \"gs\", \"gy\", \"h\", \"h2\", \"h3\", \"had\", \"hadn\", \"hadn't\", \"happens\", \"hardly\", \"has\", \"hasn\", \"hasnt\", \"hasn't\", \"have\", \"haven\", \"haven't\", \"having\", \"he\", \"hed\", \"he'd\", \"he'll\", \"hello\", \"help\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"heres\", \"here's\", \"hereupon\", \"hers\", \"herself\", \"hes\", \"he's\", \"hh\", \"hi\", \"hid\", \"him\", \"himself\", \"his\", \"hither\", \"hj\", \"ho\", \"home\", \"hopefully\", \"how\", \"howbeit\", \"however\", \"how's\", \"hr\", \"hs\", \"http\", \"hu\", \"hundred\", \"hy\", \"i\", \"i2\", \"i3\", \"i4\", \"i6\", \"i7\", \"i8\", \"ia\", \"ib\", \"ibid\", \"ic\", \"id\", \"i'd\", \"ie\", \"if\", \"ig\", \"ignored\", \"ih\", \"ii\", \"ij\", \"il\", \"i'll\", \"im\", \"i'm\", \"immediate\", \"immediately\", \"importance\", \"important\", \"in\", \"inasmuch\", \"inc\", \"indeed\", \"index\", \"indicate\", \"indicated\", \"indicates\", \"information\", \"inner\", \"insofar\", \"instead\", \"interest\", \"into\", \"invention\", \"inward\", \"io\", \"ip\", \"iq\", \"ir\", \"is\", \"isn\", \"isn't\", \"it\", \"itd\", \"it'd\", \"it'll\", \"its\", \"it's\", \"itself\", \"iv\", \"i've\", \"ix\", \"iy\", \"iz\", \"j\", \"jj\", \"jr\", \"js\", \"jt\", \"ju\", \"just\", \"k\", \"ke\", \"keep\", \"keeps\", \"kept\", \"kg\", \"kj\", \"km\", \"know\", \"known\", \"knows\", \"ko\", \"l\", \"l2\", \"la\", \"largely\", \"last\", \"lately\", \"later\", \"latter\", \"latterly\", \"lb\", \"lc\", \"le\", \"least\", \"les\", \"less\", \"lest\", \"let\", \"lets\", \"let's\", \"lf\", \"like\", \"liked\", \"likely\", \"line\", \"little\", \"lj\", \"ll\", \"ll\", \"ln\", \"lo\", \"look\", \"looking\", \"looks\", \"los\", \"lr\", \"ls\", \"lt\", \"ltd\", \"m\", \"m2\", \"ma\", \"made\", \"mainly\", \"make\", \"makes\", \"many\", \"may\", \"maybe\", \"me\", \"mean\", \"means\", \"meantime\", \"meanwhile\", \"merely\", \"mg\", \"might\", \"mightn\", \"mightn't\", \"mill\", \"million\", \"mine\", \"miss\", \"ml\", \"mn\", \"mo\", \"more\", \"moreover\", \"most\", \"mostly\", \"move\", \"mr\", \"mrs\", \"ms\", \"mt\", \"mu\", \"much\", \"mug\", \"must\", \"mustn\", \"mustn't\", \"my\", \"myself\", \"n\", \"n2\", \"na\", \"name\", \"namely\", \"nay\", \"nc\", \"nd\", \"ne\", \"near\", \"nearly\", \"necessarily\", \"necessary\", \"need\", \"needn\", \"needn't\", \"needs\", \"neither\", \"never\", \"nevertheless\", \"new\", \"next\", \"ng\", \"ni\", \"nine\", \"ninety\", \"nj\", \"nl\", \"nn\", \"no\", \"nobody\", \"non\", \"none\", \"nonetheless\", \"noone\", \"nor\", \"normally\", \"nos\", \"not\", \"noted\", \"nothing\", \"novel\", \"now\", \"nowhere\", \"nr\", \"ns\", \"nt\", \"ny\", \"o\", \"oa\", \"ob\", \"obtain\", \"obtained\", \"obviously\", \"oc\", \"od\", \"of\", \"off\", \"often\", \"og\", \"oh\", \"oi\", \"oj\", \"ok\", \"okay\", \"ol\", \"old\", \"om\", \"omitted\", \"on\", \"once\", \"one\", \"ones\", \"only\", \"onto\", \"oo\", \"op\", \"oq\", \"or\", \"ord\", \"os\", \"ot\", \"other\", \"others\", \"otherwise\", \"ou\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"outside\", \"over\", \"overall\", \"ow\", \"owing\", \"own\", \"ox\", \"oz\", \"p\", \"p1\", \"p2\", \"p3\", \"page\", \"pagecount\", \"pages\", \"par\", \"part\", \"particular\", \"particularly\", \"pas\", \"past\", \"pc\", \"pd\", \"pe\", \"per\", \"perhaps\", \"pf\", \"ph\", \"pi\", \"pj\", \"pk\", \"pl\", \"placed\", \"please\", \"plus\", \"pm\", \"pn\", \"po\", \"poorly\", \"possible\", \"possibly\", \"potentially\", \"pp\", \"pq\", \"pr\", \"predominantly\", \"present\", \"presumably\", \"previously\", \"primarily\", \"probably\", \"promptly\", \"proud\", \"provides\", \"ps\", \"pt\", \"pu\", \"put\", \"py\", \"q\", \"qj\", \"qu\", \"que\", \"quickly\", \"quite\", \"qv\", \"r\", \"r2\", \"ra\", \"ran\", \"rather\", \"rc\", \"rd\", \"re\", \"readily\", \"really\", \"reasonably\", \"recent\", \"recently\", \"ref\", \"refs\", \"regarding\", \"regardless\", \"regards\", \"related\", \"relatively\", \"research\", \"research-articl\", \"respectively\", \"resulted\", \"resulting\", \"results\", \"rf\", \"rh\", \"ri\", \"right\", \"rj\", \"rl\", \"rm\", \"rn\", \"ro\", \"rq\", \"rr\", \"rs\", \"rt\", \"ru\", \"run\", \"rv\", \"ry\", \"s\", \"s2\", \"sa\", \"said\", \"same\", \"saw\", \"say\", \"saying\", \"says\", \"sc\", \"sd\", \"se\", \"sec\", \"second\", \"secondly\", \"section\", \"see\", \"seeing\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"seen\", \"self\", \"selves\", \"sensible\", \"sent\", \"serious\", \"seriously\", \"seven\", \"several\", \"sf\", \"shall\", \"shan\", \"shan't\", \"she\", \"shed\", \"she'd\", \"she'll\", \"shes\", \"she's\", \"should\", \"shouldn\", \"shouldn't\", \"should've\", \"show\", \"showed\", \"shown\", \"showns\", \"shows\", \"si\", \"side\", \"significant\", \"significantly\", \"similar\", \"similarly\", \"since\", \"sincere\", \"six\", \"sixty\", \"sj\", \"sl\", \"slightly\", \"sm\", \"sn\", \"so\", \"some\", \"somebody\", \"somehow\", \"someone\", \"somethan\", \"something\", \"sometime\", \"sometimes\", \"somewhat\", \"somewhere\", \"soon\", \"sorry\", \"sp\", \"specifically\", \"specified\", \"specify\", \"specifying\", \"sq\", \"sr\", \"ss\", \"st\", \"still\", \"stop\", \"strongly\", \"sub\", \"substantially\", \"successfully\", \"such\", \"sufficiently\", \"suggest\", \"sup\", \"sure\", \"sy\", \"system\", \"sz\", \"t\", \"t1\", \"t2\", \"t3\", \"take\", \"taken\", \"taking\", \"tb\", \"tc\", \"td\", \"te\", \"tell\", \"ten\", \"tends\", \"tf\", \"th\", \"than\", \"thank\", \"thanks\", \"thanx\", \"that\", \"that'll\", \"thats\", \"that's\", \"that've\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"thered\", \"therefore\", \"therein\", \"there'll\", \"thereof\", \"therere\", \"theres\", \"there's\", \"thereto\", \"thereupon\", \"there've\", \"these\", \"they\", \"theyd\", \"they'd\", \"they'll\", \"theyre\", \"they're\", \"they've\", \"thickv\", \"thin\", \"think\", \"third\", \"this\", \"thorough\", \"thoroughly\", \"those\", \"thou\", \"though\", \"thoughh\", \"thousand\", \"three\", \"throug\", \"through\", \"throughout\", \"thru\", \"thus\", \"ti\", \"til\", \"tip\", \"tj\", \"tl\", \"tm\", \"tn\", \"to\", \"together\", \"too\", \"took\", \"top\", \"toward\", \"towards\", \"tp\", \"tq\", \"tr\", \"tried\", \"tries\", \"truly\", \"try\", \"trying\", \"ts\", \"t's\", \"tt\", \"tv\", \"twelve\", \"twenty\", \"twice\", \"two\", \"tx\", \"u\", \"u201d\", \"ue\", \"ui\", \"uj\", \"uk\", \"um\", \"un\", \"under\", \"unfortunately\", \"unless\", \"unlike\", \"unlikely\", \"until\", \"unto\", \"uo\", \"up\", \"upon\", \"ups\", \"ur\", \"us\", \"use\", \"used\", \"useful\", \"usefully\", \"usefulness\", \"uses\", \"using\", \"usually\", \"ut\", \"v\", \"va\", \"value\", \"various\", \"vd\", \"ve\", \"ve\", \"very\", \"via\", \"viz\", \"vj\", \"vo\", \"vol\", \"vols\", \"volumtype\", \"vq\", \"vs\", \"vt\", \"vu\", \"w\", \"wa\", \"want\", \"wants\", \"was\", \"wasn\", \"wasnt\", \"wasn't\", \"way\", \"we\", \"wed\", \"we'd\", \"welcome\", \"well\", \"we'll\", \"well-b\", \"went\", \"were\", \"we're\", \"weren\", \"werent\", \"weren't\", \"we've\", \"what\", \"whatever\", \"what'll\", \"whats\", \"what's\", \"when\", \"whence\", \"whenever\", \"when's\", \"where\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"wheres\", \"where's\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whim\", \"whither\", \"who\", \"whod\", \"whoever\", \"whole\", \"who'll\", \"whom\", \"whomever\", \"whos\", \"who's\", \"whose\", \"why\", \"why's\", \"wi\", \"widely\", \"will\", \"willing\", \"wish\", \"with\", \"within\", \"without\", \"wo\", \"won\", \"wonder\", \"wont\", \"won't\", \"words\", \"world\", \"would\", \"wouldn\", \"wouldnt\", \"wouldn't\", \"www\", \"x\", \"x1\", \"x2\", \"x3\", \"xf\", \"xi\", \"xj\", \"xk\", \"xl\", \"xn\", \"xo\", \"xs\", \"xt\", \"xv\", \"xx\", \"y\", \"y2\", \"yes\", \"yet\", \"yj\", \"yl\", \"you\", \"youd\", \"you'd\", \"you'll\", \"your\", \"youre\", \"you're\", \"yours\", \"yourself\", \"yourselves\", \"you've\", \"yr\", \"ys\", \"yt\", \"z\", \"zero\", \"zi\", \"zz\",]\n",
    "\n",
    "temp = []\n",
    "for x in df['tweet words']:\n",
    "    temp.append([ele for ele in stopwords if(ele in str(x))])\n",
    "df['tweet words'] = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ae4b06",
   "metadata": {},
   "source": [
    "In the next notebook we will begin to do modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "27106ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/Users/grahamsmith/Documents/SpringboardWork/Seamless_Twitter_Analysis/tweets with features.csv', date_format='%Y-%m-%d %H:%M:%S')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
